# Running R on HPC systems

## Open OnDemand

- Web-based platform for accessing HPC resources
  - RStudio
  - Jupyter Lab
  - Terminal
  - File browser
- Convenient for interactive development
- Very inefficient for computations

::: {.fragment}
Access via [https://ondemand.hpc.kuleuven.be/](https://ondemand.hpc.kuleuven.be/)
:::


## Batch jobs

Example "computation" script:

```{.r filename="hello_world.R"}
# Get the hostname
hostname <- Sys.info()["nodename"]

# Print the message
cat("Hello from", hostname, "!\n")
```

No suprises here


## Testing the script

Terminal:

```bash
$ module load R/4.4.0-gfbf-2023a            # <1>
$ Rscript hello.R                           # <2>
Hello from tier2-login-p-2 !
```

1. Load the R version you want to use
2. Run the script

::: {.callout-warning .fragment}
Don't run computationally intensive tasks on the login node!!!
:::


## Module system


What & why?

- Different versions of software packages
- Reproducibility

::: {.fragment}
How?

- Search for modules: `module -r spider ^R/`
- Load a module: `module load R/4.4.0-gfbf-2023a`
- List loaded modules: `module list`
- Unload all modules: `module purge`
:::


## Job script

```{.bash filename="hello_world.slurm"}
#!/usr/bin/env -S bash -l                     # <1>
#SBATCH --account=lpt2_sysadmin               # <2>
#SBATCH --nodes=1                             # <3>
#SBATCH --ntasks=1                            # <4>
#SBATCH --cpus-per-task=1                     # <5>
#SBATCH --time=00:02:00                       # <6>
#SBATCH --cluster=wice                        # <7>

module purge &> /dev/null                     # <8>
module load R/4.4.0-gfbf-2023a                # <9>

Rscript ./hello_world.R                       # <10>
```

1. Initialize the environment
2. Specify the account for credits
3. Number of nodes
4. Number of tasks
5. Number of CPUs per task
6. Maximum runtime of job
7. Cluster to run on
8. Unload all modules
9. Load the R version
10. Run the script


## Slurm speak

Slurm is

- resource manager
- job scheduler

::: {.fragment}
User(s) submit jobs to Slurm

- Job in queue
- When resources available, job starts
:::

::: {.fragment}
Efficient use of (very expensive) HPC resources
:::


## Submitting a job

```bash
$ sbatch hello_world.slurm                       # <1>
Submitted batch job 62136541 on cluster wice     # <2>
```

1. Submit the job script `hello_world.slurm`
2. Job ID is `62136541` (incremental)


## Checking job status

Show all your jobs on cluster wice:

::: {.small}
```bash
$ squeue --cluster=wice
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          62136541      wice hello_wo  mmontes  R       0:00      1 p33c20n3
```
:::

::: {.fragment}
`ST` is the job state:

- `PD`: pending
- `R`: running
- `CG`: completing
:::

::: {.fragment}
No jobs shown? All done!
:::


## Job output

Saved to file `slurm-<jobid>.out`:

```{.bash filename="slurm-62136541.out"}
SLURM_JOB_ID: 62136541
SLURM_JOB_USER: vsc30140
SLURM_JOB_ACCOUNT: lpt2_sysadmin
SLURM_JOB_NAME: hello_world.slurm
SLURM_CLUSTER_NAME: wice
SLURM_JOB_PARTITION: batch
SLURM_NNODES: 1
SLURM_NODELIST: p33c20n3
SLURM_JOB_CPUS_PER_NODE: 1
Date: Tue Aug  6 08:58:09 CEST 2024
Walltime: 00-00:02:00                              # <1>
========================================================================
Hello from p33c20n3 !                              # <2>
```

1. Info about job
2. Output of the script


## Runtime parameters

Scenario: run R script with different parameters

```bash
$ Rscript hello_world_cla.R  --name "Alice"
Hello from Alice !
$ Rscript hello_world_cla.R  --name "Bob"  --count 3
Hello from Bob !
Hello from Bob !
Hello from Bob !
```


## `optparse` package

```{.r filename="hello_world_cla.R"}
library(optparse)                                              # <1>

# Define the options
option_list <- list(                                           # <2>
  make_option(c("--name"), type="character", default="World",  # <3>
              help="Name to greet"),
  make_option(c("--count"), type="integer", default=1,         # <4>
              help="Number of times to greet")
)
opt <- parse_args(OptionParser(option_list=option_list))        # <5>

for (i in 1:opt$count) {                                       # <6>
  cat("Hello from", opt$name, "!\n")
}
```

1. Load the `optparse` package
2. Define the options
3. Option for the name
4. Option for the count
5. Parse the arguments
6. Use the arguments in list `opt`


## Job script with parameters

```{.bash filename="hello_world_cla.slurm"}
#!/usr/bin/env -S bash -l
#SBATCH --account=lpt2_sysadmin
#SBATCH --time=00:02:00
#SBATCH --cluster=wice

module purge &> /dev/null
module load R/4.4.0-gfbf-2023a

Rscript ./hello_world_cla.R  --name "Bob"  --count 3
```


## File I/O

Easiest option: relative paths

```bash
$ Rscript ./weather_analysis.R  \
      --input data/London.csv   \            # <1>
      --quantity temp_max       \
      --output tempmax_london.csv            # <2>
```

1. Input file in `data` directory, subdirectory of script's directory
2. Output file in script's directory

## R script {visibility=hidden}

```{.r filename="weather_analysis.R"}
library(optparse)
option_list <- list(
    make_option(c("-i", "--input"), type = "character",
                help = "Path to the input CSV file"),
    make_option(c("-q", "--quantity"), type = "character",
                help = "Name of the quantity to analyze (e.g., temp, tempmax, tempmin)"),
    make_option(c("-o", "--output"), type = "character",
                help = "Path to the output CSV file")
)
opt <- parse_args(OptionParser(option_list = option_list))
data <- read.csv(opt$input)
if (!(opt$quantity %in% colnames(data))) {
    stop(paste("The specified quantity", opt$quantity, "is not present in the data"))
}
data$month <- format(as.Date(data$datetime), "%m")
monthly_avg <- aggregate(data[[opt$quantity]], by = list(data$month), FUN = mean)
colnames(monthly_avg) <- c("Month", "Average")
write.csv(monthly_avg, file = opt$output, row.names = FALSE)
```

## Job script {visibility=hidden}

```{.bash filename="weather_analysis.slurm"}
#!/usr/bin/env -S bash -l
#SBATCH --account=lpt2_sysadmin
#SBATCH --time=00:02:00
#SBATCH --cluster=wice

# first clean up your environment, then load R
module purge &> /dev/null
module load R/4.4.0-gfbf-2023a

# define output directory and create it if it does not exist
OUTDIR="output"
mkdir -p $OUTDIR

# define the quantity to analyse
QUANTITY="tempmax"

Rscript ./weather_analysis.R  \
    --input data/London.csv   \
    --quantity "$QUANTITY"    \
    --output $OUTDIR/$QUANTITY.csv
```


## But wait, there is no `optparse`!

::: {.incremental}
- Not all packages are installed on HPC systems
- Install packages in VSC_DATA directory
  - Pure R/no depencies on external libraries: easy
  - Other packages: more difficult, use modules
- Packages specific for R major version/cluster/architecture
:::


## Prepare environment

Create package directory for cluster/architecture/R version
```bash
$ mkdir -p $VSC_DATA/R/wice/sapphirerapics/4.4
```
Only once per cluster/architecture/R version!

::: {.fragment}
Create R environment file in `$VSC_HOME`
```bash
$ echo "R_LIBS_USER=$VSC_DATA/R/wice/sapphirerapics/4.4" \
     > $VSC_HOME/.Renviron
```
Works only for specified cluster/architecture/R version!
:::


## Install packages

Start interactive job on cluster wice
```bash
$ srun --account=lpt2_sysadmin --time=00:30:00 \
      --cluster=wice --partition=batch_sapphirerapids \
      --pty /bin/bash -l

```

::: {.fragment}
Install the package(s)
```bash
$ module load R/4.4.0-gfbf-2023a
$ R
> install.packages("optparse")
```
:::

::: {.fragment}
If you have trouble, contact the HPC helpdesk, specify

- packages to install
- R version
- cluster and architecture
:::
